import io
from typing import Any
import streamlit as st
import cv2
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.checks import check_requirements
from ultralytics.utils.downloads import GITHUB_ASSETS_STEMS
import os
import av

# V√¥ hi·ªáu h√≥a CUDA ƒë·ªÉ ƒë·∫£m b·∫£o t∆∞∆°ng th√≠ch v·ªõi Streamlit Cloud
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

class Inference:
    """
    A class to perform object detection, image classification, image segmentation and pose estimation inference.
    """

    def __init__(self, **kwargs: Any):
        """
        Initialize the Inference class, checking Streamlit requirements and setting up the model path.
        """
        check_requirements("streamlit>=1.29.0")  # Ki·ªÉm tra y√™u c·∫ßu Streamlit

        self.st = st  # Tham chi·∫øu ƒë·∫øn module Streamlit
        self.source = None  # Ngu·ªìn video (webcam ho·∫∑c video file)
        self.enable_trk = False  # C·ªù ƒë·ªÉ b·∫≠t/t·∫Øt theo d√µi ƒë·ªëi t∆∞·ª£ng
        self.conf = 0.25  # Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y cho ph√°t hi·ªán
        self.iou = 0.45  # Ng∆∞·ª°ng IoU cho non-maximum suppression
        self.org_frame = None  # Container cho frame g·ªëc
        self.ann_frame = None  # Container cho frame ƒë√£ ƒë∆∞·ª£c ch√∫ th√≠ch
        self.vid_file_name = None  # T√™n t·ªáp video ho·∫∑c ch·ªâ s·ªë webcam
        self.selected_ind = []  # Danh s√°ch ch·ªâ s·ªë l·ªõp ƒë∆∞·ª£c ch·ªçn
        self.model = None  # Instance c·ªßa m√¥ h√¨nh YOLO
        self.uploaded_file = None  # T·ªáp video ƒë∆∞·ª£c t·∫£i l√™n

        self.temp_dict = {"model": None, **kwargs}
        self.model_path = None
        if self.temp_dict["model"] is not None:
            self.model_path = self.temp_dict["model"]

        LOGGER.info(f"Ultralytics Solutions: ‚úÖ {self.temp_dict}")

    def web_ui(self):
        """Sets up the Streamlit web interface with custom HTML elements."""
        menu_style_cfg = """<style>MainMenu {visibility: hidden;}</style>"""  # ·∫®n menu ch√≠nh
        main_title_cfg = """<div><h1 style="color:#FF64DA; text-align:center; font-size:40px; margin-top:-50px;
        font-family: 'Archivo', sans-serif; margin-bottom:20px;">Ultralytics YOLO Streamlit Application</h1></div>"""
        sub_title_cfg = """<div><h4 style="color:#042AFF; text-align:center; font-family: 'Archivo', sans-serif; 
        margin-top:-15px; margin-bottom:50px;">Experience real-time object detection on your webcam with the power 
        of Ultralytics YOLO! üöÄ</h4></div>"""

        self.st.set_page_config(page_title="Ultralytics Streamlit App", layout="wide")
        self.st.markdown(menu_style_cfg, unsafe_allow_html=True)
        self.st.markdown(main_title_cfg, unsafe_allow_html=True)
        self.st.markdown(sub_title_cfg, unsafe_allow_html=True)

    def sidebar(self):
        """Configure the Streamlit sidebar for model and inference settings."""
        with self.st.sidebar:
            logo = "https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Original.svg"
            self.st.image(logo, width=250)

        self.st.sidebar.title("User Configuration")
        self.source = self.st.sidebar.selectbox("Video Source", ("Webcam", "Uploaded Video"))
        self.enable_trk = self.st.sidebar.radio("Enable Tracking", ("Yes", "No"))
        self.conf = float(self.st.sidebar.slider("Confidence Threshold", 0.0, 1.0, self.conf, 0.01))
        self.iou = float(self.st.sidebar.slider("IoU Threshold", 0.0, 1.0, self.iou, 0.01))

        # Th√™m t√πy ch·ªçn t·∫£i l√™n video
        if self.source == "Uploaded Video":
            self.uploaded_file = self.st.sidebar.file_uploader("Upload a video file", type=["mp4", "avi", "mov"])

        col1, col2 = self.st.columns(2)
        self.org_frame = col1.empty()  # Container cho frame g·ªëc
        self.ann_frame = col2.empty()  # Container cho frame ƒë√£ ch√∫ th√≠ch

    def configure(self):
        """Configure the model and load selected classes for inference."""
        available_models = [x.replace("yolo", "YOLO") for x in GITHUB_ASSETS_STEMS if x.startswith("yolo11")]
        if self.model_path:
            available_models.insert(0, self.model_path.split(".pt")[0])
        selected_model = self.st.sidebar.selectbox("Model", available_models)

        with self.st.spinner("Model is downloading..."):
            self.model = YOLO(f"{selected_model.lower()}.pt")
            class_names = list(self.model.names.values())
        self.st.success("Model loaded successfully!")

        selected_classes = self.st.sidebar.multiselect("Classes", class_names, default=class_names[:3])
        self.selected_ind = [class_names.index(option) for option in selected_classes]
        if not isinstance(self.selected_ind, list):
            self.selected_ind = list(self.selected_ind)

    def inference(self):
        """Perform real-time object detection inference on video or webcam feed."""
        self.web_ui()
        self.sidebar()
        self.configure()

        if self.st.sidebar.button("Start"):
            stop_button = self.st.button("Stop")

            # C·∫•u h√¨nh WebRTC cho webcam
            RTC_CONFIGURATION = RTCConfiguration(
                {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
            )

            def video_frame_callback(frame):
                """X·ª≠ l√Ω frame video t·ª´ webcam ho·∫∑c file."""
                img = frame.to_ndarray(format="bgr24")

                # X·ª≠ l√Ω frame v·ªõi m√¥ h√¨nh YOLO
                if self.enable_trk == "Yes":
                    results = self.model.track(
                        img, conf=self.conf, iou=self.iou, classes=self.selected_ind, persist=True
                    )
                else:
                    results = self.model(img, conf=self.conf, iou=self.iou, classes=self.selected_ind)

                annotated_frame = results[0].plot()
                self.org_frame.image(img, channels="BGR")
                self.ann_frame.image(annotated_frame, channels="BGR")
                return av.VideoFrame.from_ndarray(annotated_frame, format="bgr24")

            if self.source == "Webcam":
                webrtc_streamer(
                    key="example",
                    mode=WebRtcMode.SENDRECV,
                    rtc_configuration=RTC_CONFIGURATION,
                    video_frame_callback=video_frame_callback
                )
            elif self.source == "Uploaded Video" and self.uploaded_file is not None:
                # L∆∞u t·ªáp video t·∫°m th·ªùi
                tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                tfile.write(self.uploaded_file.read())
                tfile.close()

                # M·ªü video b·∫±ng OpenCV
                cap = cv2.VideoCapture(tfile.name)
                while cap.isOpened():
                    ret, img = cap.read()
                    if not ret:
                        break

                    # X·ª≠ l√Ω frame v·ªõi m√¥ h√¨nh YOLO
                    if self.enable_trk == "Yes":
                        results = self.model.track(
                            img, conf=self.conf, iou=self.iou, classes=self.selected_ind, persist=True
                        )
                    else:
                        results = self.model(img, conf=self.conf, iou=self.iou, classes=self.selected_ind)

                    annotated_frame = results[0].plot()
                    self.org_frame.image(img, channels="BGR")
                    self.ann_frame.image(annotated_frame, channels="BGR")

                    # ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ m√¥ ph·ªèng th·ªùi gian th·ª±c
                    if stop_button:
                        break
                    cv2.waitKey(30)

                cap.release()
                os.unlink(tfile.name)  # X√≥a t·ªáp t·∫°m

if __name__ == "__main__":
    import tempfile
    Inference().inference()
